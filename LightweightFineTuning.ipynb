{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "f35354cd",
      "metadata": {
        "id": "f35354cd"
      },
      "source": [
        "# Lightweight Fine-Tuning Project"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "560fb3ff",
      "metadata": {
        "id": "560fb3ff"
      },
      "source": [
        "* PEFT technique: Progressive Embedding Fine-Tuning (PEFT)\n",
        "* Model: GPT-2\n",
        "* Evaluation approach: Train-Test split\n",
        "* Fine-tuning dataset: Amazon Polarity"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import Libraries"
      ],
      "metadata": {
        "id": "dP37iv9uUCC3"
      },
      "id": "dP37iv9uUCC3"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q numpy pandas datasets transformers scikit-learn torch peft"
      ],
      "metadata": {
        "id": "XeUTkJDiUWqV"
      },
      "id": "XeUTkJDiUWqV",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from datasets import load_dataset\n",
        "\n",
        "from transformers import AutoModelForSequenceClassification, AutoTokenizer, Trainer, TrainingArguments, DataCollatorWithPadding, Trainer\n",
        "\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "from peft import AutoPeftModelForSequenceClassification, LoraConfig, get_peft_model"
      ],
      "metadata": {
        "id": "eInMNmljUExz"
      },
      "id": "eInMNmljUExz",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip freeze > requirements.txt"
      ],
      "metadata": {
        "id": "uUGyGWSnUqqS"
      },
      "id": "uUGyGWSnUqqS",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Auxiliar Functions"
      ],
      "metadata": {
        "id": "2qbcNVG-a1gP"
      },
      "id": "2qbcNVG-a1gP"
    },
    {
      "cell_type": "code",
      "source": [
        "def dataset_info(dataset, subset, num_examples=1):\n",
        "    \"\"\"\n",
        "    The basic information about the Dataset\n",
        "\n",
        "    Args:\n",
        "        dataset: Dataset Object\n",
        "\n",
        "    Returns:\n",
        "        None\n",
        "    \"\"\"\n",
        "    print(f\"=== {subset.upper()} INFO ===\")\n",
        "    print(\"Size\", len(dataset[subset]))\n",
        "    print(\"Features:\", list(dataset[subset].features.keys()))\n",
        "\n",
        "    min_length = min(len(content) for content in dataset[subset][\"content\"])\n",
        "    max_length = max(len(content) for content in dataset[subset][\"content\"])\n",
        "\n",
        "    print(f\"\\nMin length of content: {min_length}\")\n",
        "    print(f\"Max length of content: {max_length}\\n\")\n",
        "\n",
        "    labels = set(dataset[subset][\"label\"])\n",
        "\n",
        "    print(\"Labels:\", labels)\n",
        "\n",
        "    frequencies = {x: dataset[subset][\"label\"].count(x) for x in set(dataset[subset][\"label\"])}\n",
        "    percentages = {x: (count / dataset[subset].num_rows) * 100 for x, count in frequencies.items()}\n",
        "\n",
        "    for key, value in percentages.items():\n",
        "        print(f\"- Label {key}: {frequencies[key]} --- {value:.2f}%\")\n",
        "\n",
        "    print(\"\\n=== EXAMPLE ===\")\n",
        "\n",
        "    for i in range(num_examples):\n",
        "      print(f\"Title: {dataset[subset]['title'][i]} --- Label: {dataset[subset]['label'][i]}\")\n",
        "      print(f\"{dataset[subset]['content'][i]}\\n\")"
      ],
      "metadata": {
        "id": "MhMce3wzEmSg"
      },
      "id": "MhMce3wzEmSg",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize(input):\n",
        "    return tokenizer(input[\"content\"], truncation=True, padding=True)"
      ],
      "metadata": {
        "id": "TX1Xd0eVa38-"
      },
      "id": "TX1Xd0eVa38-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_metrics(eval_pred):\n",
        "    predictions, labels = eval_pred\n",
        "    predictions = predictions.argmax(axis=1) if isinstance(predictions, np.ndarray) else np.argmax(predictions, axis=1)\n",
        "\n",
        "    return {\n",
        "        \"accuracy\": accuracy_score(labels, predictions),\n",
        "        \"precision\": precision_score(labels, predictions),\n",
        "        \"recall\": recall_score(labels, predictions),\n",
        "        \"f1\": f1_score(labels, predictions),\n",
        "    }"
      ],
      "metadata": {
        "id": "l2GXpNp8a512"
      },
      "id": "l2GXpNp8a512",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Dataset"
      ],
      "metadata": {
        "id": "tnb5w4MGQ_2s"
      },
      "id": "tnb5w4MGQ_2s"
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = load_dataset(\"amazon_polarity\")\n",
        "\n",
        "train_ds = dataset[\"train\"]\n",
        "test_ds = dataset[\"test\"]"
      ],
      "metadata": {
        "id": "3kYGXv7nS4Yp"
      },
      "id": "3kYGXv7nS4Yp",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_info(dataset, \"train\")"
      ],
      "metadata": {
        "id": "K7AXFIj3GAVD"
      },
      "id": "K7AXFIj3GAVD",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_info(dataset, \"test\")"
      ],
      "metadata": {
        "id": "TjZzlCXNGQD4"
      },
      "id": "TjZzlCXNGQD4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "de8d76bb",
      "metadata": {
        "id": "de8d76bb"
      },
      "source": [
        "# Loading and Evaluating a Foundation Model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "device"
      ],
      "metadata": {
        "id": "hcXzlfkr11U7"
      },
      "id": "hcXzlfkr11U7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f551c63a",
      "metadata": {
        "id": "f551c63a"
      },
      "outputs": [],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\"gpt2\").to(device)\n",
        "model.config.pad_token_id = tokenizer.pad_token_id\n",
        "\n",
        "for param in model.base_model.parameters():\n",
        "    param.requires_grad = False"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preprocessed_train_ds = train_ds.map(tokenize, batched=True)\n",
        "preprocessed_test_ds = test_ds.map(tokenize, batched=True)"
      ],
      "metadata": {
        "id": "JE6O4F9vADP4"
      },
      "id": "JE6O4F9vADP4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preprocessed_train_ds.set_format(type=\"torch\", columns=[\"label\", \"title\", \"content\", \"input_ids\", \"attention_mask\"])\n",
        "preprocessed_test_ds.set_format(type=\"torch\", columns=[\"label\", \"title\", \"content\", \"input_ids\", \"attention_mask\"])"
      ],
      "metadata": {
        "id": "Gkc0YIt2NotN"
      },
      "id": "Gkc0YIt2NotN",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "019b9f55",
      "metadata": {
        "id": "019b9f55"
      },
      "outputs": [],
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    logging_dir=\"./logs\",\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    per_device_train_batch_size=32,\n",
        "    per_device_eval_batch_size=32,\n",
        "    num_train_epochs=1,\n",
        "    load_best_model_at_end=True\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=preprocessed_train_ds,\n",
        "    eval_dataset=preprocessed_test_ds,\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=DataCollatorWithPadding(tokenizer=tokenizer),\n",
        "    compute_metrics=compute_metrics,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5176b07f",
      "metadata": {
        "id": "5176b07f"
      },
      "outputs": [],
      "source": [
        "evaluation_result = trainer.evaluate(preprocessed_test_ds)\n",
        "\n",
        "evaluation_result"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4d52a229",
      "metadata": {
        "id": "4d52a229"
      },
      "source": [
        "# Performing Parameter-Efficient Fine-Tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5775fadf",
      "metadata": {
        "id": "5775fadf"
      },
      "outputs": [],
      "source": [
        "config = LoraConfig()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "894046c0",
      "metadata": {
        "id": "894046c0"
      },
      "outputs": [],
      "source": [
        "lora_model = get_peft_model(model, config).to(device)\n",
        "\n",
        "lora_model.print_trainable_parameters()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    logging_dir=\"./logs\",\n",
        "    per_device_train_batch_size=32,\n",
        "    per_device_eval_batch_size=32,\n",
        "    num_train_epochs=5,\n",
        "    learning_rate=5e-5,\n",
        "    warmup_steps=100,\n",
        "    weight_decay=0.01\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=lora_model,\n",
        "    args=training_args,\n",
        "    train_dataset=preprocessed_train_ds,\n",
        "    eval_dataset=preprocessed_test_ds,\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=DataCollatorWithPadding(tokenizer=tokenizer),\n",
        "    compute_metrics=compute_metrics,\n",
        ")"
      ],
      "metadata": {
        "id": "OkGvY1li8W65"
      },
      "id": "OkGvY1li8W65",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "id": "kWUFBdbT8_X7"
      },
      "id": "kWUFBdbT8_X7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c4d4c908",
      "metadata": {
        "id": "c4d4c908"
      },
      "outputs": [],
      "source": [
        "lora_model.save_pretrained(\"gpt-lora\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "615b12c6",
      "metadata": {
        "id": "615b12c6"
      },
      "source": [
        "# Performing Inference with a PEFT Model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lora_model = AutoPeftModelForSequenceClassification.from_pretrained(\"gpt-lora\")\n",
        "lora_model.config.pad_token_id = tokenizer.pad_token_id"
      ],
      "metadata": {
        "id": "yvzuV6mJ8T_s"
      },
      "id": "yvzuV6mJ8T_s",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    logging_dir=\"./logs\",\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    per_device_train_batch_size=32,\n",
        "    per_device_eval_batch_size=32,\n",
        "    num_train_epochs=1,\n",
        "    load_best_model_at_end=True\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=lora_model,\n",
        "    args=training_args,\n",
        "    train_dataset=preprocessed_train_ds,\n",
        "    eval_dataset=preprocessed_test_ds,\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=DataCollatorWithPadding(tokenizer=tokenizer),\n",
        "    compute_metrics=compute_metrics,\n",
        ")"
      ],
      "metadata": {
        "id": "rKPnQFLIgzHM"
      },
      "id": "rKPnQFLIgzHM",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluation_result = trainer.evaluate(preprocessed_test_ds)\n",
        "\n",
        "evaluation_result"
      ],
      "metadata": {
        "id": "gvVrLPhGsWo0"
      },
      "id": "gvVrLPhGsWo0",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}